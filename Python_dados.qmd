---
title: "Estudo de Python e dados"
author: "Sergio Pedro Rodrigues Oliveira"
date: last-modified
date-format: DD MMMM YYYY
format:
    html:
        code-fold: true
        number-sections: true
    pdf:
      toc: false
      lof: false
      lot: false
      toc-depth: 5
      number-sections: true
      number-depth: 5
      colorlinks: true
      cite-method: biblatex
    docx:
      toc: true
      number-sections: true
      highlight-style: github
jupyter: python3
bibliography: Quarto/pythonbibliografia.bib
csl: Quarto/abnt.csl
---

\thispagestyle{empty}

\newpage
\pagenumbering{roman}

```{=latex}
\setcounter{tocdepth}{4}
\renewcommand{\contentsname}{SUMÁRIO}
\tableofcontents
```

\newpage

```{=latex}
\setcounter{tocdepth}{4}
\renewcommand{\listfigurename}{LISTA DE FIGURAS}
\listoffigures
```
\newpage

```{=latex}
\setcounter{tocdepth}{4}
\renewcommand{\listtablename}{LISTA DE TABELAS}
\listoftables
```

```{python}
#| echo: false
#| error: false
#| warning: false
from IPython.display import Markdown
from tabulate import tabulate
import math
import statistics
import numpy as np
import pandas as pd
import json
import matplotlib.pyplot as plt
```

\newpage
\pagenumbering{arabic}

# Objetivo

O objetivo deste estudo é explorar e documentar as funcionalidades essenciais das principais bibliotecas científicas do Python, como NumPy, Pandas e outras, através de exemplos práticos e casos de uso selecionados. Pretende-se consolidar o conhecimento sobre a manipulação, análise e visualização de dados, servindo como um guia de referência pessoal para futuros projetos de programação científica.

# Básico sobre o `DataFrame` do Pandas

## Introdução

O `Pandas` é uma biblioteca `Python` de código aberto para análise de dados. Ele dá a `Python` a capacidade de trabalhar com dados do tipo planilha, permitindo **carregar**, **manipular**, **alinhar** e **combinar dados** rapidamente, entre outras funções.

Para proporcionar esses recursos mais sofisticados ao `Python`, o `Pandas` introduz dois novos tipos de dados: `Series` e `DataFrame`.
  
  * `DataFrame`
  
  Representa os dados de planilhas ou retangulares completos.
  
  * `Series`
  
  Corresponde a única coluna do `DataFrame`.
  
  * Também podemos pensar em um `DataFrame` do `Pandas` como um `dicionário` ou uma coleção de objetos `Series`.

Por que você deveria usar uma linguagem de programação como `Python` e uma ferramenta como o `Pandas` para trabalhar com dados? Tudo se reduz à automação e à reprodutibilidade.

Objetivos do capítulo:

  1. Carga de um arquivo de dados simples e delimitado.
  2. Como contar quantas linhas e colunas foram carregadas.
  3. Como delimitar quais tipos de dados foram carregados.
  4. Observação de diferentes porções de dados criando subconjuntos de linhas e colunas.

\newpage

## Carregando seu primeiro conjunto de dados

Dado um conjunto de dados inicialmente o carregamos e começamos a observar sua estrutura e contéudo.

O modo mais simples de observar um conjunto de dados é analisar e criar subconjuntos de linhas e colunas específicas. Podemos ver quais tipos de informação estão armazenadas em cada coluna, e começar a procurar padrões por meio de estatísticas descritivas agregadas.

Como o **Pandas** não faz parte da biblioteca-padrão de Python, devemos dizer antes ao Python que carregue a biblioteca (`import`):

```
import pandas as pd
```

Quando trabalhamos com funções **Pandas**, usar o alias `pd` para `pandas` é uma prática comum.

Com a biblioteca carregada, podemos usar a função `read_csv` para carregar um arquivo de dados **CSV**. Para acessar a função `read_csv` do Pandas, usamos a notação de ponto.

```{python}
# Por padrão, a função read_csv lerá um arquivo separado por vírgula;
# Nosso dados Gapminder estão separados por tabulações;
# Podemos usar o parâmetro sep a representar uma tabulação com \t
import pandas as pd # Importa a biblioteca pandas como 'pd'.

# --- Carregamento e Inspeção Inicial ---
df = pd.read_csv('./Data/Cap_01/gapminder.tsv', sep='\t')
# Carrega o arquivo TSV em um DataFrame, usando tabulação como separador.

# Usamos o método head para que Python nos mostre as 5 primeiras linhas
print(df.head())
```

\newpage

* Função `type()`:

  Podemos verificar se estamos trabalhando com um `DataFrame` do Pandas usando a função embutida `type` (isto é, se ele vem diretamente de Python, e não de algum pacote, como o Pandas).

  A função `type()` é conveniente quando começamos a trabalhar com vários tipos diferentes de objetos Python e precisamos saber em qual objeto estamos trabalhando no momento. 

  ```{python}
  print(type(df))
  ```

* Atributo `shape`:

  No momento, o conjunto de dados que carregamos esta salvo como um objeto `DataFrame` do **Pandas**, e é relativamente pequeno.

  Todo objeto `DataFrame` tem um atributo `shape` que nos dará o número de linhas e de colunas desse objeto.

  O atributo `shape` devolve uma tupla[^tupla] na qual o primeiro valor é o número de linhas e o segundo é a quantidade de colunas.

  Com base nesse resultado anteior, podemos ver que nosso conjunto de dados Gapminder tem 1704 linhas e 6 colunas.

  Como `shape` é um atributo de `DataFrame`, e não uma função ou um método, não há parênteses após o ponto. Se você cometer o erro de colocar parênteses depois do atributo `shape`, um erro será devolvido.

  ```{python}
  # Obtém o número de linhas e colunas
  print(df.shape)
  ```

[^tupla]: Uma tupla é semelhante a uma `list`, pois ambas podem armazenar informações heterogêneas. A principal diferença é que o conteúdo de uma tupla é "imutável", o que significa que ela não pode ser alterada. As tuplas também são criadas com parênteses, ().

\newpage

* Atributo `columns`:

  Em geral, quando observamos um conjunto de dados pela primeira vez, queremos saber quantas linhas e colunas há (acabamos de fazer isso).

  Para ter uma noção de quais informações ele contém, devemos observar as colunas.

  Os nomes das colunas, assim como `shape`, são especificados usando o atributo `columns` do objeto dataframe.

  ```{python}
  # Obtém os nomes das colunas
  print(df.columns)
  ```

* Atributo `dtypes`:

  O objeto `DataFrame` do **Pandas** é semelhante a objetos do tipo `DataFrame` que se encontra em outras linguagens (por exemplo, Julia e R).

  Toda coluna (`Series`) deve ser do mesmo tipo, enquanto cada linha pode conter tipos variados.

  Em nosso exemplo atual, podemos esperar que a coluna `country` só contenha strings e que `year` contenha inteiros. No entanto, é melhor garantir que isso seja verdade usando o atributo `dtypes` ou o método `info()`.

  O atributo `dtypes` de um `DataFrame` **Pandas** retorna uma `Series` que descreve o tipo de dado de cada coluna do `DataFrame`. Ele é útil para inspecionar os tipos de dados inferidos ou atribuídos às suas colunas, o que é crucial para operações corretas e eficientes.

  ```{python}
  # Obtém o dtype de cada coluna
  print(df.dtypes)
  ```

\newpage

* Método `info()`:

  O método `info()` de um `DataFrame` **Pandas** é uma ferramenta essencial para obter um resumo conciso e detalhado do seu `DataFrame`. Ele imprime um resumo conciso do `DataFrame`, incluindo:

  ```{python}
  #| echo: false
  #| error: false
  #| warning: false
  #| label: tbl-infoPandas
  #| tbl-cap: Informações do método info() do Pandas

  from IPython.display import Markdown
  from tabulate import tabulate
  table = [["Tipo de índice","Informações sobre o índice \n(por exemplo, RangeIndex)."],
         ["Número de entradas (linhas)","Quantas linhas seu DataFrame possui."],
         ["Número de colunas","Quantas colunas seu DataFrame tem."],
         ["Contagem de valores não nulos por coluna","Para cada coluna, informa quantos valores \nnão são nulos. \nIsso é crucial para identificar dados faltantes."],
         ["Dtype (tipo de dado) de cada coluna","Semelhante ao atributo dtype, \nmas apresentado de forma mais organizada."],
         ["Uso de memória","A quantidade de memória que o DataFrame \nestá utilizando."]
         ]
  Markdown(tabulate(
  table, 
  headers=["Informação","Discrição"],
  colalign=("left","left")
  ))
  ```

  ```{python}
  # Obtém mais informações sobre nossos dados
  print(df.info())
  ```

\newpage

```{python}
#| echo: false
#| error: false
#| warning: false
#| label: tbl-pdvspy
#| tbl-cap: Tipos do Pandas versus tipos de Python

from IPython.display import Markdown
from tabulate import tabulate
table = [["object","string","Cadeia de caracteres, usado para representar texto."],
         ["int64","int","Números inteiros."],
         ["float64","float","Números com decimais."],
         ["datetime64","datetime","`datetime` trata-se de uma biblioteca-padrão de Python \n(ou seja, não é carregado por padrão e deve ser importado). \nRepresenta pontos específicos no tempo."]
         ]
Markdown(tabulate(
  table, 
  headers=["Tipo do Pandas","Tipo de Python","Discrição"],
  colalign=("left","left","left")
))
```

\newpage

## Observando colunas, linhas e células

Agora que somos capazes de carregar um arquivo de dados simples, queremos inspecionar o seu conteúdo. Podemos exibir o conteúdo do dataframe com `print`, mas com os dados de hoje em dia, com frequência, haverá células demais para ser possível compreender todas as informações exibidas. Em vez disso, a melhor maneira de observar nossos dados é inspecioná-los por partes, observando vários subconjuntos dos dados.

Já vimos que podemos usar o método `head()` de um dataframe para observar as cinco primeiras linhas de nossos dados. Isso é conveniente para ver se os dados foram carregados de modo apropriado e para ter uma noção de cada uma das colunas, seus nomes e o conteúdo. Às vezes, porém, talvez queiramos ver somente linhas, colunas e valores específicos de nossos dados.

### Obtendo subconjuntos de colunas

Se quiser analisar várias colunas, especifique-as com base nos nomes, nas posições ou em intervalos.

#### Obtendo subconjuntos de colunas pelo nome {.unnumbered}

Se quiser observar apenas uma coluna específica de nossos dados, podemos acessá-la usando colchetes.

```{python}
# Obtém somente a coluna country e a salva em sua própria variável
country_df = df['country']

# Mostra as 5 primeiras observações
print(country_df.head())
```

\newpage

```{python}
# Mostra as 5 últimas observações
print(country_df.tail())
```

Para específicar várias colunas pelo nome, devemos passar uma `list` Python entre os colchetes. Isso pode parecer um pouco estranho, pois haverá dois conjuntos de colchetes.

```{python}
# Observando country, continent e year
subset = df[['country', 'continent', 'year']]
print(subset.head())
```

```{python}
# Mostra as 5 últimas observações
print(subset.tail())
```

Mais uma vez, é possível optar por exibir todo o dataframe subset usando `print`.

\newpage

#### Obter subconjuntos de colunas pela posição dos índices não funciona mais no Pandas v0.20 {.unnumbered}

Ocasionalmente, talvez você queira obter uma coluna em particular com base em sua posição, e não em seu nome. Por exemplo, pode querer a primeira ("country") e a terceira ("year") colunas, ou somente a última ("gdpPercap").

No `pandas v0.20` não é mais possível passar uma lista de inteiros entre colchetes para obter subconjuntos de colunas. Por exemplo, `df[[1]]`, `df[[0,-1]]` e `df[list(range(5))]` não funcionam mais. Há outras formas de obter subconjuntos de colunas, mas não baseadas na técnica usada para obter subconjuntos de linhas.

\newpage

### Obtendo subconjuntos de linhas

Podemos obter subconjuntos de linhas de várias maneiras, pelos nomes ou pelos índices das linhas. A @tbl-il apresenta uma visão geral rápida dos diversos métodos.

```{python}
#| echo: false
#| error: false
#| warning: false
#| label: tbl-il
#| tbl-cap: Diferentes métodos para indexação de linhas (ou de colunas).

from IPython.display import Markdown
from tabulate import tabulate
table = [["`loc`","Subconjunto baseado no rótulo do índice \n(**nome** da linha)."],
         ["`iloc`","Subconjunto baseada no índice da linha \n(**número** da linha)."],
         ["`ix` (não funciona mais no \n`Pandas v0.20`)","Subconjunto baseado no rótulo do índice ou \nno índice da linha."]
         ]
Markdown(tabulate(
  table, 
  headers=["Método para obtenção de subconjuntos","Discrição"],
  colalign=("left","left")
))
```

#### Obtendo subconjuntos de linhas pelo rótulo dos índices: `loc` {.unnumbered}

Vamos observar uma parte de nossos dados `Gapminder`.

```{python}
print(df.head())
```

A esquerda do DataFrame exibido, vemos o que parece ser os números das linhas. Essa lista de valores sem coluna é o rótulo dos índices do dataframe.

Pense no rótulo dos índices como um nome de coluna, mas para linhas em vez de colunas. Por padrão, o Pandas preencherá os rótulos dos índices com os números das linhas (observe que a contagem começa em 0).

Um exemplo comum em que os rótulos dos índices das linhas não são iguais ao número das linhas ocorre quando trabalhamos com dados de séries temporais. Nesse caso, o rótulo dos índices será algum tipo de timestamp. Por exemplo, manteremos os valores default, que são os números das linhas.

Podemos usar o atributo `loc` do dataframe para obter subconjuntos de linhas com base no rótulo dos índices.

```{python}
# Obtém a primeira linha
# Python começa a contar de 0
print(df.loc[0])
```

```{python}
# Obtém a centesima linha
# Python começa a contar de 0
print(df.loc[99])
```

\newpage

**Para obtér a última linha**, uma alternativa seria passar -1 para `loc`, porém acarretaria num erro. Ao passar -1 para `loc` causará um erro, pois o código procurará a linha cujo rótulo de índice (nesse caso, número da linha) seja "-1", e esse valor não existe no nosso exemplo.

Em vez disso, podemos usar um pouco de Python para calcular o número de linhas e passar esse valor para `loc`.

```{python}
# Obtém a última linha (corretamente)
# Usar o primeiro valor dado por shape para obter o número de linhas
number_of_rows = df.shape[0]

# Subtrai 1 do valor, pois queremos obter o número do último índice
last_row_index = number_of_rows - 1

# Obtem agora o subconjunto usando o índice da última linha
print(df.loc[last_row_index])
```

Como alternativa, podemos usar o método `tail` para devolver a última linha, em vez de usar o default de 5.

```{python}
# Método tail, devolvendo a última linha
print(df.tail(n=1))
```

Observe que, quando usamos `tail()` e `loc`, os resultados foram exibidos de modo diferentes. Vamos observar o tipo devolvido quando usamos esses métodos.

\newpage

```{python}
subset_loc = df.loc[0]
subset_head = df.head(n=1)

# type usando loc para uma linha
print("type usando loc para uma linha:")
print(type(subset_loc))

# type usando head para uma linha
print("\ntype usando head para uma linha:")
print(type(subset_head))
```

No ínicio desse capítulo, mencionamos que o Pandas introduziu dois novos tipos de dados em Python. Conforme o método que usamos e a quantidade de linhas retornada, o Pandas devolverá um objeto diferente. O modo como o objeto é exibido pela tela pode ser um indicador do tipo, mas sempre é melhor usar a função `type()` por garantia.

\newpage

**Obtenção de subconjuntos com várias linhas**. Assim como para as colunas, podemos selecionar várias linhas.

```{python}
# Selecione a primeira, a centesima e a milésima linha
# Observe os colchetes duplos, semelhante a sintaxe usada para
#obter subconjuntos com várias colunas
print(df.loc[[0,99,999]])
```

\newpage

#### Obtendo subconjuntos de linhas pelo número das linhas: `iloc` {.unnumbered}

`iloc` faz o mesmo que `loc`, mas é usado para obter subconjuntos com base no número de índice das linhas.

Em nosso exemplo atual, `iloc` e `loc` se comportarão exatamente do mesmo modo, pois os rótulos dos índices são os números das linhas. Tenha em mente, porém, que os rótulos dos índices não necessariamente têm de ser os números das linhas.

```{python}
# Obtém a segunda linha
print(df.iloc[1])
```

```{python}
# Obtém a centésima linha
print(df.iloc[99])
```

Observe que quando colocamos 1 na lista, na verdade, obtemos a segunda linha, e não a primeira. Isso está de acordo com o comportamento de indexação a partir do 0 de Python, o que significa que o primeiro item de um contêiner é o índice 0 (ou seja, o item 0 do contêiner).

\newpage

Com `iloc` podemos passar `-1` para **obter a última linha** - algo que não era possível com `loc`.

```{python}
# Usando -1 para obter a última linha
print(df.iloc[-1])
```

Como antes, é possível passar **uma lista de inteiros para obter várias linhas**.

```{python}
# Obtém a primeira, a centésima e a milésima linha
print(df.iloc[[0, 99, 999]])
```

\newpage

#### Obtenção de subconjuntos de linhas com `ix` não funciona mais no Pandas v0.20 {.unnumbered}

O atributo `ix` não funciona em versões de Pandas posteriores a v0.20, pois pode ser confuso. Apesar disso, faremos uma revisão rápida de `ix` nesta seção para que a explicação fique completa.

Podemos pensar em `ix` como uma combinação de `loc` e `iloc`, pois permite que tenhamos subconjuntos por rótulo ou por inteiro. Por padrão, ele procura rótulos. Se não puder encontrar o rótulo correspondente, ele recorrerá ao uso de indexação por inteiros. Isso pode ser causa de muitas confusões, e, assim, esse recurso foi removido.

O código que usa `ix` se parecerá exatamente com o código escrito quando `loc` e `iloc` são usados.

```
# Primeira linha
df.ix[0]

# Centésima linha
df.ix[99]

# Primeira, centésima e milésima linhas
df.ix[[0,99,999]]
```

\newpage

### Combinando tudo

Os atributos `loc` e `iloc` podem ser usados para obter subconjuntos de colunas, linhas ou de ambos.

A sintaxe geral de `loc` e `iloc` faz uso de colchetes com uma vírgula. A parte à esquerda da vírgula são os valores das linhas para o subconjunto; a parte à direita são os valores das colunas. Ou seja, `df.loc[[rows],[columns]]` ou `df.iloc[[rows],[columns]]`.

#### Obtendo subconjuntos de colunas {.unnumbered}

Se quiser usar técnicas para obter subconjuntos somente de colunas, use a sintaxe de fatiamento (slicing) de Python. Temos de fazer isso porque, se estivermos gerando subconjuntos de colunas, teremos todas as linhas da coluna especificadas. Portanto precisamos de um método para capturar todas as linhas.

A sintaxe de fatiamento de Python usa dois-pontos, isto é, :. Se tivermos apenas dois-pontos sozinhos, o atributo se referirá a tudo. Assim, se quisermos obter somente a primeira coluna usando a sintaxe `loc` ou de `iloc`, podemos escrever algo como `df.loc[:,[columns]]` para obter o subconjunto da(s) coluna(s).

```{python}
# Obtendo um subconjunto de colunas com loc
# Observe a posição dos dois-pontos
# Ele é usado para selecionar todas as linhas
subset = df.loc[:,['year','pop']]
print(subset.head())
```

\newpage

```{python}
# Obtendo um subconjunto de colunas com iloc
# iloc nos permitirá usar inteiros
# -1 selecionará a última coluna
subset = df.iloc[:,[2,4,-1]]
print(subset.head())
```

\newpage

#### Obtendo subconjuntos de colunas por intervalo {.unnumbered}

Podemos usar a função embutida `range` para criar um intervalo de valores em Python. Desse modo, é possível especificar os valores de início e fim, e Python criará automaticamente um intervalo com os valores entre eles.

Por padrão, todo valor entro o início e o fim (**inclusive à esquerda, não inclusive a direita**) será criado, a comenos que você especifique um passo.

Em Python 3, a função `range` devolve um gerador.

Se estiver usando Python 2, a função `range` devolverá uma lista e a função `xrange` devolve um gerador.

Se observarmos o código apresentado antes, veremos que subconjuntos de colunas foram obtidos usando uma lista de inteiros. Como `range` devolve um gerador, é preciso convertê-lo em uma lista antes.  
`list(range(5))`

Observe que, quando `range(5)` é achamado, cinco inteiros são devolvidos: 0-4.

```{python}
# Cria um intervalo de inteiros de 0 a 4 inclusive, [0,5)
small_range = list(range(5))
print(small_range)
```

```{python}
# Obtém um subconjunto de dataframe usando o intervalo
subset = df.iloc[:,small_range]
print(subset.head()) 
```

\newpage

```{python}
# Cria um intervalo de 3 a 5 incluvie, [3,5] ou [3,6)
small_range = list(range(3,6))
print(small_range)
subset = df.iloc[:,small_range]
print(subset.head())
```

**Pergunta** (**Desafio 1**):
    
  **O que acontecerá se você especificar um intervalo que estiver além do número de colunas existente?**

**Resposta**:
    
  Erro do tipo `IndexError`.

\newpage

Mais uma vez, observe que os valores são especificados de modo que **o intervalo é inclusivo à esquerda, mas não a direita**.

```{python}
# Cria um intervalo de 0 a 5 inclusive, com inteiros alternados [0,6)
small_range = list(range(0,6,2))
subset = df.iloc[:,small_range]
print(subset.head())
```

Converter um gerador em uma lista é um pouco complicado; podemos usar a sintaxe de fatiamento de Python para dar um jeito nisso.

\newpage

#### Fatiando colunas {.unnumbered}

A sintaxe de **fatiamento de Python**, **:**, **é semelhante à sintaxe de** `range`. Em vez de usar uma função que especifique os valores de início, fim e o passo, delimitados por vírgula, separamos os valores com dois-pontos.

Se você entendeu o que estava acontecendo com a função `range` que usamos antes, o fatiamento então poderá ser visto como um atalho para fazer o mesmo.

Exemplo `range`:

```{python}
small_range = list(range(3))
subset = df.iloc[:,small_range]
print(subset.head())
```

Exemplo fatiamento de Python:

```{python}
# Fatia as três primeiras colunas
subset = df.iloc[:,:3]
print(subset.head())
```

\newpage

Exemplo `range`:

```{python}
small_range = list(range(3,6))
subset = df.iloc[:,small_range]
print(subset.head())
```

Exemplo fatiamento de Python:

```{python}
# Fatia as colunas de 3 a 5 inclusive, [3,6)
subset = df.iloc[:,3:6]
print(subset.head())
```

\newpage

Exemplo `range`:

```{python}
small_range = list(range(0,6,2))
subset = df.iloc[:,small_range]
print(subset.head())
```

Exemplo fatiamento de Python:

```{python}
# Fatia as cinco primeiras colunas alternadamente
subset = df.iloc[:,:6:2]
print(subset.head())
```

\newpage

#### Obtendo subconjuntos de linhas e de colunas {.unnumbered}

Temos usado dois-pontos, :, em `loc` e em `iloc` à esquerda da vírgula. Quando fazemos isso, selecionamos todas as linhas de nosso dataframe. No entanto, podemos optar por colocar valores à esquerda da vírgula se quisermos selecionar linhas específicas, além de colunas específicas.

```{python}
# Usando loc
print(df.loc[42,'country'])
```

```{python}
# Usando iloc
print(df.iloc[42,0])
```

Certifique-se de que não se esquecerá das diferenças entre `loc` (rótulo do índice, nome) e `iloc` (índice, número).

Observe agora como `ix` pode ser confuso. É bom que ele não esteja mais funcionando.

\newpage

#### Obtendo subconjuntos de várias linhas e de colunas {.unnumbered}

Podemos combinar a sintaxe de obtenção de subconjuntos de linhas e de colunas com a sintaxe de subconjuntos de várias linhas e várias colunas a fim de obter fatias de nossos dados.

```{python}
# Obtém a primeira, a centésima e a milésima linha
# da primeira, quarta e sexta coluna;
# As colunas que esperamos obter são
# country, lifeExp e gdpPercap
print(df.iloc[[0,99,999],[0,3,5]])
```

**Atenção!!!**

Em meu trabalho, tento passar os nomes das colunas para obter subconjuntos de dados, sempre que possível. Essa abordagem deixa o código mais legível, pois não será necessário observar o vetor de nomes das colunas para saber qual índice está sendo especificado.

Além disso, usar índices absolutos (número da coluna) pode resultar em problemas caso a ordem das colunas seja alterada por algum motivo.

Essa é somente uma regra geral, uma vez que haverá exceções em que usar a posição do índice será uma opção melhor (por exemplo, para concatenar dados).

```{python}
# Se usarmos os nomes das colunas diretamente,
# o código será um pouco mais facil de ler
# Observe agora que temos que usar loc ao invés de iloc
print(df.loc[[0,99,999],['country','lifeExp','gdpPercap']])
```

**Usar** `loc` **sempre que possível!!!**

\newpage

Lembre-se de que podemos usar a sintaxe de fatiamento na parte referente às linhas dos atributos `loc` e `iloc`.

```{python}
print(df.loc[10:13,['country','lifeExp','gdpPercap']])
```

\newpage

## Cálculos agrupados e agregados

Se você já trabalhou com outras bibliotecas numéricas ou linguagens, saberá que muitos cálculos estatísticos básicos estarão disponíveis na biblioteca ou embutidos na linguagem. Vamos observar novamente nossos dados Gapminder.

```{python}
print(df.head(n=10))
```

**Perguntas estatísticas**

Há várias perguntas iniciais que podemos nos fazer:

1. Para cada ano em nossos dados, qual era a expectativa de vida média? Qual é a expectativa de vida média, a população e o GDP?
2. E se estratificarmos os dados por continente e fizermos os mesmos cálculos?
3. Quantos países estão listados para cada continente?

\newpage

### Médias agrupadas

Para responder as perguntas que acabaram de ser propostas, precisamos fazer um cálculo **agrupado** (isto é, **agregado**). Em outras palavras, temos de fazer um cálculo, seja uma média ou uma contagem de frequência, mas aplicá-lo em cada subconjuntode uma variável.

Outro modo de pensar em cálculos agrupados é vê-los como um processo do tipo **separar-aplicar-combinar**.

   * Inicialmente, separamos nossos dados em várias partes;
   * Em seguida, aplicamos uma função (ou cálculo) de nossa escolha em cada parte separada;
   * E, por fim, combinamos todos os cálculos individuais em um único dataframe.

Fazemos processamentos agrupados/agregados usando o método `groupby` nos dataframe.

```{python}
# Para cada ano em nossos dados, qual era a expectativa de vida média?
# Para responder a essa pergunta,
# temos que separar nossos dados em partes, de acordo com o ano;
# em seguida, obtemos a coluna 'lifeExp' e calculamos a média

#Agrupamento (year) 
#Separação/subconjunto (lifeExp) 
#Aplicar (média)

print(df.groupby('year')['lifeExp'].mean())
```

\newpage

Vamos detalhar a instrução que usamos nesse exemplo.

  * Em primeiro lugar, criamos um objeto **agrupado**. Observe que, se exibíssemos o dataframe agrupado, o Pandas devolveria somente a posição na memória.

    ```{python}
    grouped_year_df = df.groupby('year')
    print(type(grouped_year_df))
    print(grouped_year_df)
    ```

  * A partir dos dados agrupados, podemos obter um **subconjunto** das colunas de nosso interesse, nas quais queremos fazer os cálculos. Para responder à nossa pergunta, precisamos da coluna `lifeExp`. Podemos usar os métodos de obtenção de subconjuntos.

    ```{python}
    grouped_year_df_lifeExp = grouped_year_df['lifeExp']
    print(type(grouped_year_df_lifeExp))
    print(grouped_year_df_lifeExp)
    ```

    Observe que agora temos uma série (pois pedimos apenas uma coluna) cujo conteúdo é agrupado (em nosso exemplo por ano).
  
  * Por fim, sabemos que a coluna `lifeExp` é do tipo `float64`. Uma operação que podemos **executar** em um vetor de números e **calcular** a média para obter o resultado que desejamos.

    ```{python}
    mean_lifeExp_by_year = grouped_year_df_lifeExp.mean()
    print(mean_lifeExp_by_year.head(n=10))
    ```

\newpage

Podemos executar um conjunto semelhante de cálculos para a população e o GDP, pois eles são dos tipos `int64` e `float64`, respectivamente. Mas e se quiséssemos agrupar e estratificar os dados com base em mais de uma váriavel? E se quiséssemos fazer o mesmo cálculo em várias colunas? Podemos partir do código anterior apresentado e usar uma lista.

```{python}
# A barra invertida nos permite quebrar uma linha longa de código Python
# em várias linhas.
# df.groupby(['year','continent'])[['lifeExp','gdpPercap']].mean()
# é o mesmo que o código a seguir
multi_group_var = df.\
  groupby(['year','continent'])\
  [['lifeExp','gdpPercap']]\
  .mean()
print(multi_group_var.head(n=20))
```

\newpage

Os dados de saída estão agrupados por ano e por continente. Para cada par ano-continente, calculamos a expectativa de vida média e o GDP médio. 

Os dados também são exibidos de modo um pouco diferente. Observe que os "nomes das colunas" de ano e continente não estão na mesma linhaque os "nomes das colunas" de expectativa de vida e GPD. Há uma certa estrutura hierárquica entre os índices das linhas de ano e continente.

Caso precise "achatar" o dataframe, use o método `reset_index`.

```{python}
flat = multi_group_var.reset_index()
print(flat.head(n=20))
```

\newpage

### Condatodes de frequência agrupados

Outra tarefa comum relacionada aos dados é calcular frequências.

Podemos usar os métodos `nunique` e `value_counts`, respectivamente, para obter contadores de valores únicos e contadores de frequência em uma `Series` do Pandas.

* Método `nunique`:

  ```{python}
  # Uso de nunique (number unique, ou número de únicos)
  # para calcular o número de valores únicos em uma série
  print(df.groupby('continent')['country'].nunique())
  ```

* Método `value_counts`:

  ```{python}
  # Nova série que mostra cada valor único
  # e sua respectiva frequência (quantidade de ocorrências).
  print(df['continent'].value_counts())
  ```

Resumo da diferença:

  * `nunique()` diz quantos valores únicos existem. O resultado é um número.

  * `value_counts()` diz quais são os valores únicos e quantas vezes cada um aparece. O resultado é uma série.

\newpage

## Plotagem básica

As visualizações são extremamente importantes em quase todos os passos do processamento de dados. Elas nos ajudam a identificar tendências nos dados quando estamos tentando entendê-los e limpá-los, além de contribuir para a apresentação de nossas descobretas finais.

Vamos observar as expectativas de vida anuais da população mundial novamente.

```{python}
global_yearly_life_expectancy = df.groupby('year')['lifeExp'].mean()
print(global_yearly_life_expectancy)
```

\newpage

Podemos usar o Pandas para criar algumas plotagens básicas.

```
global_yearly_life_expectancy.plot()
```

![Plotagem básica no Pandas mostrando a expectativa de vida média no tempo.](./Imagens/Cap_01-Basic_dataframe/Expectativa_vida_media.png){width=400}

\newpage

## Conclusão

Explicamos como carregar um conjunto de dados simples e começar a analisar observações específicas.

Tenha em mente que, quando fazemos análise de dados, o objetivo é gerar resultados reproduzíveis, sem fazer tarefas repetitivas. As linguagens de scripting lhe oferecem esses recursos e essa flexibilidade.

Nesse processo, conhecemos alguns dos recursos fundamentais de programação e as estruturas de dados que Python tem a nos oferecer.

Também vimos um modo rápido de obter estatísticas agregadas e fazer plotagens.

\newpage

# Estrutura de dados do Pandas

## Introdução

O capítulo anterior apresentou os objetos `Dataframe` e `Series` do Pandas. Essas estruturas de dados assemelham-se aos contêineres de dados primitivos de Python (lista e dicionários, estruturas de dados básicas do Python que podem armazenar coleções de objetos) para indexação e rótulos, mas têm recursos adicionais que facilitam trabalhar com os dados.

### Mapa Conceitual {.unnumbered}

1. Conhecimento prévio
    1. Contêineres (`list` e `dict`)
    2. Uso de funções
    3. Obtenção de subconjuntos e indexação
2. Carga de dados manual
3. `Series`
   1. Criando uma série
      * `dict`
      * `ndarray`
      * escalar
      * listas
   2. Fatiamento 
4. `Dataframe`

\newpage

## Criando seus próprios dados

### Criando uma Series

A `Series` do Pandas é um **contêiner unidimensional**, semelhante à `list` embutida de Python.

É o tipo de dado que representa cada coluna do `Dataframe`. A @tbl-pdvspy lista os possíveis `dtypes` das colunas do `Dataframe` de Pandas. **Cada coluna em um** `dataframe` **deve ter o mesmo** `dtypes`.

Por ser possível pensar em `dataframe` como um dicionário de objetos `Series`, em que cada `key` é o nome da coluna e `value` é a `Series`, podemos concluir que uma Series é muito semelhante a uma `list` Python, exceto que todos os elementos devem ser do mesmo `dtype`. As pessoas que já usaram a biblioteca `numpy` perceberão que esse é o mesmo comportamento exibido por ndarray.

O modo mais fácil de criar uma `Series` é passando uma `list` Python.

Se passamos uma lista com tipos misturados, a representação mais comum será usada.

Em geral, `dtype` (tipo) da `Series` será um `object`.

```{python}
import pandas as pd

s = pd.Series(['Banana',42])
print(s)
```

Observe que o "número da linha" é exibido à esquerda. Na verdade, esse é o `index` da série. É semelhante ao nome e ao índice da linha que vimos sobre `dataframes`.

\newpage

Isso implica que podemos atribuir realmente um "nome" aos valores de nossa série.

```{python}
# Atribui valores de índice manualmente em uma série
# passando uma list Python
s = pd.Series(['Wes McKinney','Creator of Python'],
index=['Person','Who'])

print(s)
```

\newpage

**Perguntas**

 1. O que acontecerá se você usar outros contêineres Python como `list`, `tuple`, `dict` ou ate mesmo o `ndarray` da biblioteca `numpy`?

   * Quando você usa uma `list` (lista) ou `tuple` (tupla) para criar uma `Series`, o pandas simplesmente pega os elementos na ordem em que eles aparecem e os usa para popular a `Series`. O índice padrão é gerado automaticamente, começando do `0` e indo até `n-1`, onde `n` é o número de elementos.
  
     ```{python}
     print("#------------list------------#")
     s = pd.Series(['Wes McKinney', 'Creator of Pandas'])
     print(s)
     ```

     ```{python}
     print("#----------tuple-----------#")
     s = pd.Series(('Wes McKinney', 'Creator of Pandas'))
     print(s)
     ```


   * O `dict` é um caso especial e muito útil. Quando você cria uma `Series` a partir de um dicionário, o pandas usa as chaves do dicionário como o índice da Series e os valores como os dados. Isso permite que você crie uma `Series` já com rótulos significativos, o que é ótimo para dados categorizados.
  
     ```{python}
     print("#----------------dict----------------#")
     dict_dados = {'a':100,'b': 200, 'c':300}
     s = pd.Series(dict_dados)
     print(s)
     ```


   * O `ndarray`[^ndarray] é o contêiner mais eficiente para o pandas. O pandas foi construído sobre o `NumPy`, então o `ndarray` é o formato subjacente de dados para a maioria das operações. Quando você usa um `ndarray` para criar uma Series, o processo é extremamente rápido, pois não há necessidade de converter o tipo de dado. O índice padrão também é gerado automaticamente.

     ```{python}
     print("#----------ndarray----------#")
     numpy_dados = np.array([5,6,7])
     s = pd.Series(numpy_dados)
     print(s)
     ```

\newpage

 2. O que acontecerá se você passar um `index` com os contêineres?

   * Quando os dados vêm de uma `list`, `tuple` ou `ndarray`, o pandas simplesmente combina os dados com o `index` fornecido. O pandas espera que o `index` tenha o mesmo número de elementos que o contêiner de dados.
   
     ```{python}
     index_dados = ['a','b','c']
     dados_lista = [100,200,300]

     print("#----------------list----------------#")
     s = pd.Series(dados_lista,index=index_dados)
     print(s)
     ```

     ```{python}
     index_dados = ['a','b','c']
     dados_tupla = (100,200,300)

     print("#----------------tuple----------------#")
     s = pd.Series(dados_tupla,index=index_dados)
     print(s)
     ```

     ```{python}
     index_dados = ['a','b','c']
     dados_ndarray = np.array([100,200,300])

     print("#----------------ndarray----------------#")
     s = pd.Series(dados_ndarray,index=index_dados)
     print(s)
     ```

   * Quando você passa um dict junto com um index, o pandas não usa as chaves do dicionário para criar o índice da Series. Em vez disso, ele usa o index fornecido para selecionar e reordenar os valores do dicionário.
  
     ```{python}
     index_dict = ['c','a','d','b']
     dict_dados = {'a':100,'b': 200, 'c':300}

     print("#----------------dict----------------#")
     s = pd.Series(dict_dados,index=index_dict)
     print(s)
     ```

\newpage

 3. Passar um `index` quando usamos um dict sobrescreverá o índice? Ou ele ordenará os valores?

   O index que você passa ao criar a `Series` não sobrescreve os rótulos do dicionário. Em vez disso, ele ordena os valores e determina quais deles serão incluídos na `Series` final.

[^ndarray]:`ndarray` é o nome oficial do tipo de dado (a classe) que o NumPy usa para representar arrays multidimensionais. `np.array()` é a função que você chama para criar uma instância (um objeto) dessa classe `ndarray`.

\newpage

### Criando um Dataframe

Conforme mencionamos podemos pensar em um `Dataframe` como um dicionário de objetos `Series`. É por isso que os dicionários são o modo mais comum de criar um `Dataframe`.

`key` representa o nome da coluna, enquanto os `values` são o conteúdo.

* `key` representa o nome da coluna;
* Os `values` são o conteúdo.

```{python}
scientists = pd.DataFrame({
  'Nome': ['Rosaline Franklin','William Gosset'],
  'Occupation':['Chemist','Statistician'],
  'Born':['1920-07-25','1876-06-13'],
  'Died':['1958-04-16','1937-10-16'],
  'Age':[37,61]
})

print(scientists)
```

A ordem das colunas ao criar um DataFrame a partir de um dicionário não é garantida nas versões mais antigas do Python (anteriores ao 3.7). A partir do Python 3.7, a ordem de inserção dos elementos em dicionários é preservada.

\newpage

**Ordem das colunas e nome dos índices:**

   * Se consultarmos a documentação do `Dataframe`, veremos que é possível usar o parâmetro `columns` ou específicar a ordem das colunas. **Ordena as colunas**.
   * Se quisermos usar colunas `name` para o índice da linha, podemos usar o parâmetro index. **Nomeia o índice**.

```{python}
scientists = pd.DataFrame({
'Occupation':['Chemist','Statistician'],
'Born':['1920-07-25','1876-06-13'],
'Died':['1958-04-16','1937-10-16'],
'Age':[37,61]
},
index=['Rosaline Franklin','William Gosset'],
columns=['Occupation','Born','Died','Age'])

print(scientists)
```

\newpage

Antes do Python 3.7, os dicionários padrão (`dict`) não mantinham a ordem de inserção dos itens. Se você quisesse um dicionário que lembrasse a ordem em que os itens foram adicionados, precisava usar o `OrderedDict()`, classe do módulo `collections`.

`from collections import OrderedDict`

A partir do Python 3.7, os dicionários padrão passaram a manter a ordem de inserção por padrão. Isso significa que, na maioria dos casos, você não precisa mais usar o `OrderedDict` para essa finalidade.

Contudo, para efeito de estudo, segue o exemplo de uso do `OrderedDict`:

```{python}
from collections import OrderedDict

# Observe os parênteses após OrderedDict
# Então passamos uma lista com duas tuplas

scientists = pd.DataFrame(OrderedDict([
  ('Nome', ['Rosaline Franklin','William Gosset']),
  ('Occupation',['Chemist','Statistician']),
  ('Born',['1920-07-25','1876-06-13']),
  ('Died',['1958-04-16','1937-10-16']),
  ('Age',[37,61])
])
)

print(scientists)
```

\newpage

## Series

Vimos como o método de fatiamento afeta o `type` do resultado. Se usarmos o atributo `loc` para gerar o subconjunto com a primeira linha de nosso `dataframe` `scientists`, obteremos um objeto `Series`.

Vamos recriar inicialmente o nosso dataframe de exemplo:

```{python}
scientists = pd.DataFrame({
'Occupation':['Chemist','Statistician'],
'Born':['1920-07-25','1876-06-13'],
'Died':['1958-04-16','1937-10-16'],
'Age':[37,61]
},
index=['Rosaline Franklin','William Gosset'],
columns=['Occupation','Born','Died','Age'])

print(scientists)
```

Agora selecionaremos um cientista pelo rótulo do índice da linha:

```{python}
first_row = scientists.loc['William Gosset']

print("\nTipo do objeto: ")
print(type(first_row))

print("\nObjeto: ")
print(first_row)
```

\newpage

Quando uma série é exibida (isto é, a sua representação em string), o índice é representado como a primeira "coluna", e os valores são mostrados a segunda "coluna". Há muitos atributos e métodos associados a um objeto `Series`.

Apresentação Objeto `Series`:

   * Primeira coluna = índices (`index`)
   
   * Segunda coluna = valores (`values`)

Dois exemplos de atributos são `index` e `values`:

   * Atributo `index`:
     ```{python}
     # index é um atributo, não precisa de parênteses
     print(first_row.index)
     ```

   * Atributo `values`:
     ```{python}
     # values é um atributo, não precisa de parênteses
     print(first_row.values)
     ```

Um exemplo de um **método** de `Series` é `keys`, que é um alias (apelido) para o atributo `index`:

```{python}
# keys é um método, precisa de parênteses
print(first_row.keys())
```

\newpage

A essa altura, talvez você tenha perguntas sobre a sintaxe de `index`, `values` e `keys`.

  * Podemos pensar nos **atributos** como propriedades de um objeto (nesse exemplo, nosso objeto é uma `Series`).  
  `index` e `values`.
  
  *  Podemos pensar nos **métodos** como um cálculo ou uma operação executada.  
  `keys`.

A sintaxe de subconjuntos para `loc`, `iloc` e `ix` é composta de todos os atributos. É por isso que essa sintaxe não depende de um conjunto de parênteses, (), mas de colchetes, [].

A sintaxe de subconjuntos para os indexadores `loc`, `iloc` e `ix` no pandas é feita usando colchetes, []. Isso ocorre porque eles são usados para a operação de indexação (seleção de dados), que é a sintaxe padrão de Python para esse fim, e não para a chamada de métodos, que usaria parênteses, ().

Como `keys` é um método, se quiséssemos obter a primeira chave (que é também o primeiro índice), usaríamos colchetes após a chamada do método.

```{python}
# Obter o primeiro índice usando atributo index
print(first_row.index[0])
```

```{python}
# Obter a primeira key usando método keys
print(first_row.keys()[0])
```

\newpage

Alguns atributos de uma `Series` estão listados na @tbl-attseries.

```{python}
#| echo: false
#| error: false
#| warning: false
#| label: tbl-attseries
#| tbl-cap: Alguns dos atributos de uma Series

from IPython.display import Markdown
from tabulate import tabulate
table = [["`loc`","Subconjunto usando o valor de índice."],
          ["`iloc`","Subconjunto usando a posição de índice."],
          ["`ix`","Subconjunto usando valor e/ou posição de índice."],
          ["`dtype` ou `dtypes`","Tipos de conteúdo de `Series`."],
          ["`T`","Transposta da série."],
          ["`shape`","Dimensões dos dados."],
          ["`size`","Número de elementos em `Series`."],
          ["`values`","`ndarray` ou dado semelhante de `Series`."]]
Markdown(tabulate(
  table, 
  headers=["Atributo de Series","Descrição"],
  colalign=("left","left")
  ))
```

\newpage

### `Series` é semelhante a `ndarray`

* A estrutura de dados do Pandas conhecida como `Series` é muito semelhante ao `numpy.ndarray`.
* Por sua vez, muitos métodos e funções que atuam em um `numpy` funcionarão também em uma `Series`.
* As vezes, uma `Series` poderá ser referenciada como um "vetor".

#### Métodos de `Series`

Vamos inicialmente obter uma série da coluna "Age" de nosso dataframe `scientists`.

```{python}
# Obtém a coluna "Age"
ages = scientists['Age']
print(ages)
```

O `numpy` é uma biblioteca de processamento cientifíco que, em geral, lida com vetores numéricos. Como podemos pensar em uma `Series` como uma extensão de `numpy.ndarray`, há uma sobreposição de atributos e de métodos. Quando temos uma vetor de números, há cálculos comuns que podem ser executados.

\newpage

Exemplos de métodos no Pandas:

* `mean()` - Média:
  ```{python}
  print(ages.mean())
  ```

* `min()` - Mínimo:
  ```{python}
  print(ages.min())
  ```

* `max()` - Máximo:
  ```{python}
  print(ages.max())
  ```

* `std()` - Desvio-padrão:
  ```{python}
  print(ages.std())
  ```

`mean`, `min`, `max` e `std` também são métodos em `numpy.ndarray`. Alguns métodos se Series estão listados na @tbl-mseries.

\newpage

### Subconjuntos com booleanos: `Series`

Podemos usar índices específicos para obter subconjuntos de nossos dados (como visto anteriormente). Apenas raramente, porém, saberemos o índice exato das linhas e colunas para obter um subconjunto dos dados. Em geral, você estará procurando valores que satisfaçam (ou não) aum cálculo ou uma observação em particular.

```{python}
#| echo: false
#| error: false
#| warning: false
#| label: tbl-mseries
#| tbl-cap: Alguns métodos que podem ser executados em uma `Series`

from IPython.display import Markdown
from tabulate import tabulate
table = [["`append`","Concatena duas ou mais `Series`."],
         ["`corr`","Calcula uma correlação com outra `Series`.*"],
         ["`cov`","Calcula uma covariância com outra `Series`.*"],
         ["`describe`","Calcula estatísticas resumidas.*"],
         ["`drop_duplicates`","Devolve uma `Series` sem duplicações."],
         ["`equals`","Determina se uma `Series` tem os mesmos elementos."],
         ["`get_values`","Obtém valores da `Series`; o mesmo que o atributo `values`."],
         ["`hist`","Desenha um histograma."],
         ["`isin`","Verifica se valores estão contidos em uma `Series`."],
         ["`min`","Devolve o valor mínimo."],
         ["`max`","Devolve o valor máximo."],
         ["`mean`","Devolve a média aritmética."],
         ["`median`","Devolve a mediana."],
         ["`mode`","Devolve a(s) moda(s)."],
         ["`quantile`","Devolve o valor em um dado quantil."],
         ["`replace`","Substitui valores da `Series` por um valor especificado."],
         ["`sample`","Devolve uma amostra aleatória de valores da `Series`."],
         ["`sort_values`","Ordena valores."],
         ["`to_frame`","Converte uma `Series` em um `DataFrame`."],
         ["`transpose`","Devolve a transposta."],
         ["`unique`","Devolve um `numpy.ndarray` de valores únicos."]]
Markdown(tabulate(
  table, 
  headers=["Métodos de `Series`","Descrição"],
  colalign=("left","left")
  ))
```

*Indica se valores ausentes serão automaticamente descartados.

\newpage

Para explorar esse processo, vamos usar um conjunto de dados maior.

```{python}
scientists = pd.read_csv('./Data/Cap_02/scientists.csv')
```

Acabamos de ver como podemos calcular métricas descritivas básicas de vetores.

O método `describe` calculará várias estatísticas descritivas com uma única chamada de método.

```{python}
ages = scientists['Age']
print(ages)
```

* `describe` - Estatísticas básicas:

  ```{python}
  # Obtém estatísticas básicas
  print(ages.describe())
  ```

* `mean` - Média aritmética:

  ```{python}
  # Média de todas as idades
  print(ages.mean())
  ```

\newpage

E se quisermos obter o subconjunto de nossas idades identificando aquelas que estejam acima da média?

```{python}
print(ages[ages > ages.mean()])
```

Vamos analisar essa instrução e observar o que `ages > ages.mean()` devolve.

```{python}
print(ages > ages.mean())
```

```{python}
print(type(ages > ages.mean()))
```

Essa instrução devolve uma `Series` com `dtype` igual a `bool` (booleano, verdadeiro ou falso). Em outras palavras, podemos não só obter subconjunto de valores usando rótulos e índices, mas também especificar um vetor com valores booleanos.

Python tem muitas funções e métodos. Conforme o modo como estão implementados, eles poderão devolver rótulos, índices ou booleanos. Tenha esse ponto em mente quando conhecer novos métodos e tentar combinar várias partes em seu trabalho.

\newpage

Se quisermos podemos fornecer manualmente um vetor de `bool`s para obter um subconjunto de nossos dados.

```{python}
# Obtém os índices 0, 1, 4, 5 e 7
manual_bool_values = [True,True,False,False,True,True,False,True]
print(ages[manual_bool_values])
```

\newpage

### Operações são alinhadas e vetorizadas automaticamente (Broadcasting)

Se você não tem familiaridade com programação, acharia estranho que `ages > ages.mean()` devolva um vetor sem nenhum laço `for`.

Muitos dos métodos que funcionam em `Series` (e em `DataFrames` também) são vetorizados, o que significa que atuam em todo vetor simultaneamente.

Essa abordagem deixa o código mais legível e, em geral, há otimizações disponíveis para deixar os cálculos mais rápidos.

#### Vetores de mesmo tamanho

Se você executar uma operação entre dois vetores de mesmo tamanho, o vetor resultante será um cálculo feito com os vetores, elemento a elemento.

```{python}
# Soma vetores do mesmo tamanho
print(ages + ages)
```

```{python}
# Multiplica vetores do mesmo tamanho
print(ages * ages)
```

\newpage

#### Vetores com inteiros (escalares)

Ao executar uma operação em um vetor usando um escalar, esse será usado em todos os elementos do vetor.

```{python}
# Soma vetor e um escalar
print(ages + 100)
```

```{python}
# Multiplicação de um vetor por um escalar
print(ages * 2)
```

\newpage

#### Vetores com tamanhos diferentes

Quando estiver trabalhando com vetores de tamanhos diferentes, o comportamento dependerá do `type` dos vetores.

Em uma `Series`, os vetores executarão uma operação de acordo com o índice correspondente. O resto do vetor resultante será preenchido com um valor "ausente", representado por `NaN`, que quer dizer "*Not a Number*" (não é um número).

Esse tipo de comportamento, é chamado de **Broadcasting**.

```{python}
print(ages + pd.Series([1,100]))
```

Com outros `types`, os formatos devem coincidir, ou retornará um erro.

```
import numpy as np

# Isto causará um erro
print(ages + np.array([1,100]))
```

\newpage

#### Vetores com rótulos de índice comuns (alinhamento automático)

Um aspecto interessante no Pandas é o modo como o alinhamento de dados é quase sempre automático.

Se for possível, os dados sempre se alinharão de acordo com o rótulo do índice na execução de ações.

```{python}
# ages conforme aparecem nos dados
print(ages)
```

```{python}
# ages invertendo a ordem dos índices
rev_ages = ages.sort_index(ascending=False)
print(rev_ages)
```

\newpage

Se executarmos uma operação usando `ages` e `rev_ages`, ela ainda será conduzida elemento a elemento, mas os vetores serão alinhados antes de a operação ser realizada.

```{python}
# Saída de referência para mostrar o alinhamento dos rótulos de índice
print(ages * 2)
```

```{python}
# Observe que obtemos os mesmos valores
# apesar de o vetor estar invertido
print(ages + rev_ages)
```

**O índice é a referência para as operações e há um realinhamento (ordenamento)**.

\newpage

## Dataframe

O `DataFrame` é o objeto mais comum do Pandas. Podemos pensar nele como o modo Python de armazenar dados do tipo planilha.

Muitos dos recursos da estrutura de dados `Series` se aplicam ao `DataFrame`.

### Subconjuntos com booleanos: `DataFrames`

Assim como pudemos obter um subconjunto de uma `Series` usando um vetor *booleano*, podemos obter um subconjunto de um `DataFrame` com um `bool`.

```{python}
# Vetores booleanos servem para obter subconjuntos de linhas
print(scientists[scientists['Age'] > scientists['Age'].mean()])
```

Quando você usa uma lista de booleanos para selecionar linhas em um `DataFrame` do Pandas, o número de valores `True` e `False` deve ser exatamente igual ao número total de linhas do `DataFrame`.

O conceito de *broadcasting* não se aplica aqui. A lista booleana atua como uma máscara de seleção, onde cada `True` ou `False` corresponde a uma linha específica. Se a máscara tiver um tamanho diferente do `DataFrame`, o Pandas não saberá quais linhas incluir ou ignorar, e isso resultará em um erro (`IndexError`).

```{python}
# 8 valores passados como um vetor booleanos
# 3 linhas devolvidas
print(scientists.loc[[True,True,False,True,False,False,False,False]])
```

\newpage

A @tbl-msubconjdf resumo os diversos tipos de métodos para obtenção de subconjuntos.

```{python}
#| echo: false
#| error: false
#| warning: false
#| label: tbl-msubconjdf
#| tbl-cap: Tabela de métodos para obtenção de subconjuntos de DataFrame

from IPython.display import Markdown
from tabulate import tabulate
table = [["`df[column_name]`","Única coluna."],
  ["`df[[column1,column2,...]]`","Várias colunas."],
  ["`df.loc[row_label]`","Linha pelo rótulo do índice da linha (nome da linha)."],
  ["`df.loc[label1,label2,...]`","Várias linhas pelos rótulos do índice."],
  ["`df.iloc[row_number]`","Linha pelo número da linha."],
  ["`df.iloc[row1,row2,...]`","Várias linhas pelos números das linhas."],
  ["`df.ix[label_or_number]`","Linha pelo rótulo do índice ou pelo número."],
  ["`df.ix[lab_num1,lab_num2,...]`","Várias linhas pelos rótulos de índice ou pelos números."],
  ["`df[bool]`","Linha baseada em `bool`."],
  ["`df[bool1,bool2,...]`","Várias linhas baseadas em `bool`."],
  ["`df[start:stop:step]`","Linhas baseadas em notação de fatiamento."]
  ]
Markdown(tabulate(
table, 
headers=["Sintaxe","Resultado da seleção"],
colalign=("left","left")
))
```

*Observe que `ix` não funciona mais depois do Pandas v0.20.

\newpage

### Operações são alinhadas e vetorizadas automaticamente (*Broadcasting*)

O Pandas aceita *broadcasting*, disponibilizado pela biblioteca `numpy`. Essencialmente, ele descreve o que acontece quando realizamos operações entre objetos do tipo array, que é o caso de `Series` e `DataFrame`. Esses comportamentos dependem do tipo do objeto, de seu tamanho e de qualquer rótulo assoaciado a ele.

Inicialmente, vamos criar subconjuntos de nosso dataframe.

```{python}
first_half = scientists[:4]
second_half = scientists[4:]
```

```{python}
print(first_half)
```

```{python}
print(second_half)
```

\newpage

Quando executamos uma ação em um dataframe com um escalar, há uma tentativa de aplicar a operação em cada célula do dataframe.

#### Escalar {.unnumbered}

Nesse exemplo, os números serão multiplicados por 2 e as *strings* serão **duplicadas** (esse é o comportamento usual do Python com *strings*).

```{python}
# Multiplicar por um escalar
print(scientists * 2)
```

\newpage

#### Somar - método `.add()` {.unnumbered}

Se seus dataframes tiverem somente valores numéricos e você quiser "somar" os valores célula a célula, o método `add` poderá ser usado.

O método `.add()` em pandas é uma maneira muito útil de somar dataframes elemento a elemento. Ele é especialmente flexível porque, ao contrário do operador `+`, ele tem um parâmetro chamado `fill_value`.

Esse parâmetro é extremamente útil quando os dataframes têm índices (linhas) ou colunas diferentes. Se uma célula em um dataframe não tiver uma "correspondente" no outro dataframe, o `fill_value` será usado para preencher o valor ausente antes de fazer a soma. Isso evita que o resultado seja `NaN` (*Not a Number*) para essas células, que é o comportamento padrão do operador `+`.

```{python}
# DataFrame 1
df1 = pd.DataFrame({
    'A': [10, 20, 30],
    'B': [40, 50, 60]
}, index=['X', 'Y', 'Z'])

print("DataFrame 1:")
print(df1)
```

```{python}
# DataFrame 2
df2 = pd.DataFrame({
    'A': [5, 10, 15],
    'C': [2, 4, 6]  # Note a coluna 'C', que não existe em df1
}, index=['X', 'Y', 'W'])  # Note a linha 'W', que não existe em df1

print("DataFrame 2:")
print(df2)
```

```{python}
# Usando .add() com fill_value
# Preenche os valores ausentes com 0 para que a soma ocorra
df_soma = df1.add(df2, fill_value=0)

print("Resultado da soma com .add(fill_value=0):")
print(df_soma)
```

\newpage

## Fazendo alterações em Series e em Dataframe

Agora que já conhecemos várias maneiras de obter subconjuntos e fatiar nossos dados (veja @tbl-msubconjdf), podemos alterar nossos objetos de dados.

### Adicionando mais colunas

O `type` das colunas `Born` e `Died` é `object`, ou seja são strings.

```{python}
print(scientists['Born'].dtype)
```

```{python}
print(scientists['Died'].dtype)
```

É possível converter as strings em um tipo `datatime` apropriado para que possamos executar operações comuns de data e hora (por exemplo, obter as diferenças entre datas ou calcular a idade de uma pessoa).

Você pode fornecer o seu próprio `format` caso tenha uma data com um formato específico. Uma lista de variáveis `format` pode ser encontrada na documentação do módulo `datetime` de Python.

O formato da data que vamos trabalhar tem o aspecto "AAAA-MM-DD", portanto podemos usar o formato '%Y-%m-%d'.

```{python}
# Formata a coluna 'Born' como datetime
born_datetime = pd.to_datetime(scientists['Born'], format='%Y-%m-%d')
print(born_datetime)
```

```{python}
died_datetime = pd.to_datetime(scientists['Died'], format='%Y-%m-%d')
print(died_datetime)
```

\newpage

Se quiséssemos, poderiamos criar um novo conjunto de colunas contendo as representações como `datetime` das datas que são `object` (string).

O exemplo a seguir usa a sintaxe de atribuição múltipla do Python.

```{python}
scientists['born_dt'],scientists['died_dt'] = (born_datetime, died_datetime)
print(scientists.head())
```

```{python}
print(scientists.shape)
```

\newpage

### Alterando diretamente uma coluna
### Descartando valores

\newpage

## Exportando e importando dados

## Conclusão

\newpage

# Introdução à plotagem

\newpage

# Referências