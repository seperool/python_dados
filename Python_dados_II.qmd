---
title: "Estudo de Python e dados II"
subtitle: "Manipulação de dados: Preparação de dados, dados ausentes e Tidy data"
author: "Sergio Pedro Rodrigues Oliveira"
date: last-modified
date-format: DD MMMM YYYY
lang: pt
format:
    html:
        code-fold: true
        number-sections: true
    pdf:
      toc: false
      lof: false
      lot: false
      toc-depth: 5
      number-sections: true
      number-depth: 5
      colorlinks: true
      cite-method: biblatex
    docx:
      toc: true
      number-sections: true
      highlight-style: github
jupyter: python3
bibliography: Quarto/pythonbibliografia.bib
csl: Quarto/abnt.csl
---

\thispagestyle{empty}

\newpage
\pagenumbering{roman}

```{=latex}
\setcounter{tocdepth}{4}
\renewcommand{\contentsname}{SUMÁRIO}
\tableofcontents
```

\newpage

```{=latex}
\setcounter{tocdepth}{4}
\renewcommand{\listfigurename}{LISTA DE FIGURAS}
\listoffigures
```
\newpage

```{=latex}
\setcounter{tocdepth}{4}
\renewcommand{\listtablename}{LISTA DE TABELAS}
\listoftables
```

```{python}
#| echo: false
#| error: false
#| warning: false

# Bibliotecas para o funcionamento do documento Quarto

from IPython.display import Markdown
from tabulate import tabulate
import math
import statistics
import numpy as np
import pandas as pd
import json
import matplotlib.pyplot as plt
import seaborn as sns
```

\newpage
\pagenumbering{arabic}

# Objetivo

O objetivo deste estudo é explorar e documentar as funcionalidades essenciais das principais bibliotecas científicas do Python, como `NumPy`, `Pandas` e outras, através de exemplos práticos e casos de uso selecionados. Pretende-se consolidar o conhecimento sobre a manipulação, análise e visualização de dados, servindo como um guia de referência pessoal para futuros projetos de programação científica.

\newpage

# Preparação dos dados

## Introdução

A essa altura, você deverá ser capaz de carregar dados no `Pandas` e fazer algumas visualização básica. Essa parte do livro tem como foco várias tarefas de limpeza dos dados. Começaremos com a preparação de um conjunto de dados para análise por meio da combinação de diversos conjuntos.

### Mapa conceitual {.unnumbered}

#. Conhecimento prévio
   #. Carga de dados;
   #. Obtenção de subconjuntos de dados;
   #. Funções e métodos de classe.

### Objetivos {.unnumbered}

Este capítulo abordará:
   
   #. *Tidy data* (dados organizados);
   
   #. Concatenação de dados;
   
   #. Combinação (merge) de conjunto de dados.

```{mermaid}
%%| label: fig-prepdados
%%| fig-cap: "Preparação de dados, principais tópicos."

graph TD
    A[Preparação dos dados] --> B[Tidy Data]
    A --> C[Concatenação de dados]
    A --> D[merge]
```

\newpage

## Tidy data

Hadley Wickham, um dos mais proeminentes membros da comunidade **R**, fala sobre a ideia de *tidy data* (dados organizados). 

Com efeito, ele escreveu um artigo sobre esse conceito no *Journal of Statistical Software*. *Tidy data* é um framework para estruturar [conjuntos de dados]{.underline} a fim de que sejam facilmente [analisados]{.underline}. É usado principalmente como um objetivo a que devemos visar quando [limpamos os dados]{.underline}. Depois que você compreender o que é o conceito de *tidy data*, esse conhecimento fará com que a [coleta de dados]{.underline} seja muito mais fácil.

Então o que é *tidy data*? O artigo de Hadley Wickham o define como um conceito que atende aos seguintes critérios:

#. "**Cada observação deve formar uma linha**" (Observation)

   Uma observação é o conjunto de todas as medidas feitas em uma única unidade (ex: uma pessoa em um exame, um país em um ano específico).

   * O erro comum: Repetir a mesma observação em várias colunas ou espalhar os dados de uma mesma pessoa em tabelas diferentes sem necessidade.

   * O modo Tidy: Se você está analisando a saúde de pacientes, cada linha deve representar um paciente em um momento específico.

#. "**Cada variável deve formar uma coluna**" (Variable)

   Uma variável é um atributo que você mede (ex: Peso, Data, Temperatura).

   * O erro comum: Ter colunas chamadas "Janeiro", "Fevereiro" e "Março". Aqui, o nome da variável é "Mês", e Janeiro/Fevereiro são apenas valores.

   * O modo Tidy: Criar uma coluna única chamada Mes onde os valores são listados.

#. "**Cada tipo de unidade observacional forma uma tabela**"

   Esta regra foca na [organização macro]{.underline}.

   Sobre o terceiro critério do tidy data, [as observações devem ser coerentes com a tabela]{.underline}, tornando-a objetiva quanto ao tipo de informação que deve armazenar. A ideia é que [a tabela tenha um propósito único]{.underline}; ao misturar assuntos diferentes em uma mesma estrutura, fere-se a normalização dos dados.

   * O erro comum: Misturar dados de "Clientes" com dados de "Vendas" na mesma tabela, causando redundância (ex: repetir o endereço do cliente toda vez que ele compra algo).

   * O modo Tidy: Ter uma tabela para Clientes e outra para Vendas, relacionando-as por um ID. Isso facilita a manutenção e evita erros de digitação.

\newpage

### Combinando conjuntos de dados

Começaremos com o último critério de Hadley Wickham para *tidy data*: "cada tipo de unidade de observação forma uma tabela".

Quando os dados estão organizados, é necessário combinar várias tabelas para responder a uma pergunta. Por exemplo, pode haver uma tabela separada que armazene informações de empresas e outra tabela contendo preços de ações. Se quisermos observar os preços de todas as ações no mercado de tecnologia, talvez antes tenhamos de encontrar todas as empresas de tecnologia na tabela de informações sobre empresas e então combinar esses dados com os preços das ações a fim de obter as informações de que precisamos para responder à nossa pergunta.

Os dados podem ter sido separados em tabelas distintas para reduzir a quantidade de informações redundantes (não precisamos armazenar informações sobre as empresas em cada entrada de preço das ações), mas essa organização implica que, como analistas de dados, teremos de combinar os dados relevantes por conta própria para responder à nossa pergunta.

Em outras ocasiões, um único conjunto de dados pode estar dividido em várias partes. Por exemplo, em dados de séries temporais, cada data pode estar em um arquivo separado. Em outro caso, um arquivo pode ter sido separado em partes para que os arquivos individuais fossem menores. Talvez você precise combinar dados de diversas origens para responder a uma pergunta (por exemplo, como combinar latitudes em longitudes com CEPs). Nos dois casos, você terá que combinar dados em um único dataframe de análise.

\newpage

## Concatenação

Uma das maneiras mais (conceitualmente) fáceis de combinar dados é por meio da concatenação.

Podemos pensar na concatenação como uma junção de linhas ou colunas em seus dados. Essa abordagem é possível se seus dados estiverem separados em partes ou se você fez um cálculo que queira concatenar ao seu conjunto de dados existente.

A [concatenação]{.underline} é feita usando a [função `concat` do `Pandas`]{.underline}.

### Adicionando linhas

Vamos começar com alguns conjuntos de dados de exemplo para que você veja o que realmente acontece.

```{python}
import pandas as pd

df1 = pd.read_csv("Cap_04-Preparacao_dados/01-Concatenacao/concat_1.csv")
df2 = pd.read_csv("Cap_04-Preparacao_dados/01-Concatenacao/concat_2.csv")
df3 = pd.read_csv("Cap_04-Preparacao_dados/01-Concatenacao/concat_3.csv")

print("dataframe_csv_1:")
print(df1)
print("dataframe_csv_2:")
print(df2)
print("dataframe_csv_3:")
print(df3)
```

A operação de empilhar dataframes uns sobre os outros é feita com a função `concat` do `Pandas`. Todos os dataframes a serem concatenados são passados em uma `list`.

```{python}
row_concat = pd.concat([df1,df2,df3])
print(row_concat)
```

Como podemos ver, `concat` empilha cegamente os dataframes. Se observar os nomes das linhas (isto é, seus índices), verá que eles são apenas uma versão empilhada dos índices originais das linhas.

Se aplicarmos os diversos métodos para obtenção de subconjuntos, os subconjuntos serão obtidos conforme esperado.

```{python}
#Obtém o subconjunto da quarta linha do dataframe concatenado
print(row_concat.iloc[3,])
```

\newpage

O que acontece se você usar `loc` para obter o subconjunto do novo dataframe?

A função `loc` pega os subconjuntos pelo rótulo (nome da linha), logo pega todos os rótulos com mesmo nome, pegando assim 3 linhas diferentes com mesmo nome.

```{python}
print(row_concat.loc[3])
```

\newpage

#### Concatenar `Series`

Anteriormente apresentamos o processo de criar uma `Series`. No entanto, se criássemos uma nova série para concatenar em um dataframe, ela não seria concatenada corretamente.

```{python}
#Criar uma nova linha de dados
new_row_series = pd.Series(['n1','n2','n3','n4'])
print(new_row_series)
```

```{python}
#Tentando adicionar a nova linha em um dataframe
print(pd.concat([df1,new_row_series]))
```

O primeiro detalhe que você perceba são os valores [`NaN`]{.underline}. É simplesmente o modo Python de representar um ["valor ausente"]{.underline}.

Esperávamos concatenar nossos novos valores como uma linha, mas isso não aconteceu. De fato, nosso código não só não concatenou os valores como uma linha, como também criou uma nova coluna totalmente desalinhada em relação ao restante dos dados.

Se pararmos para pensar no que está acontecendo nesse caso, poderemos ver que o resultado, na verdade, faz sentido. Em primeiro lugar, se observarmos os novos índices adicionados, percebemos que são muito semelhantes aos resultados que obtivemos quando concatenamos dataframes antes. Os índices do objeto `new_row_series` são análogos aos números das linhas do dataframe.

Além disso, como nossa série não tem uma coluna correspondente, nosso `new_row_series` foi adicionado em uma nova coluna.

\newpage

[Para corrigir esse problema]{.underline}, podemos [transformar a nossa série em um dataframe]{.underline}. Esse dataframe contém uma linha de dados, e os nomes das colunas são aqueles com as quais os dados serão associados.

```{python}
#Observe os colchetes duplos
new_row_df = pd.DataFrame([['n1','n2','n3','n4']],columns=['A','B','C','D'])
print(new_row_df)
```

```{python}
print(pd.concat([df1,new_row_df]))
```

\newpage

`concat` é uma função genérica capaz de concatenar vários [dados de uma só vez]{.underline}.

Se você tiver de [concatenar um único objeto a um dataframe existente]{.underline}, a função `append` poderá cauidar dessa tarefa.

[O método `.append()` foi descontinuado]{.underline} nas versões mais recentes do Pandas (acima da 2.0). Atualmente, a forma correta e recomendada de juntar DataFrames é usar o pd.concat().

* Usando um `DataFrame`:

```
print(df1.append(df2))
```

* Usando um `DataFrame` com uma só linha:

```
print(df1.append(new_row_df))
```

* Usando um dicionário Python:

```
data_dict = {
   'A': 'n1',
   'B': 'n2',
   'C': 'n3',
   'D': 'n4'
}

print(df1.append(data_dict, ignore_index=True))
```

\newpage

#### Ignorando o índice

No último exemplo, quando adicionamos um `dict` em um dataframe, tivemos que usar [o parâmetro `ignore_index`]{.underline}. Se observarmos com mais atenção, veremos que [o índice da linha também foi incrementado em 1]{.underline}, e não houve repetição de um valor de índice anterior.

Se simplesmente queremos concatenar os dados, podemos usar o parâmetro [`ignore_index` para reiniciar o índice da linha após a concatenação]{.underline}.

```{python}
row_concat_i = pd.concat([df1,df2,df3],
ignore_index=True)
print(row_concat_i)
```

\newpage

### Adicionando colunas

#### Concatenando colunas - axis {.unnumbered}

Concatenar colunas é muito semelhante a concatenar linhas. A principal diferença esta no parâmetro `axis` da função `concat`.

O valor [default de `axis` é `0`]{.underline}, portanto ele concatenará os [dados nas linhas]{.underline}. Entretanto, se passarmos [`axis=1`]{.underline} para a função, [os dados serão concatenados nas colunas]{.underline}.

```{python}
col_concat = pd.concat([df1,df2,df3],
axis=1)
print(col_concat)
```

#### Subconjuntos colunas {.unnumbered}

Se tentarmos obter um [subconjunto de dados com base nos nomes das colunas]{.underline}, teremos um resultado similar aquele obtido se concatenássemos por linha e gerássemos um subconjunto pelo índice da linhas.

```{python}
print(col_concat['A'])
```

\newpage

#### Adicionar uma única coluna {.unnumbered}

[Adicionar uma única coluna]{.underline} em um dataframe pode ser feito diretamente, [sem usar nenhuma função específica do Pandas]{.underline}.

Basta específicar [um novo nome de coluna e o vetor]{.underline} que você quer que seja atribuído a essa nova coluna.

```{python}
col_concat['new_col_list'] = ['n1','n2','n3','n4']
print(col_concat)
```

```{python}
col_concat['new_col_series'] = pd.Series(['n1','n2','n3','n4'])
print(col_concat)
```

Usar a função `concat` continua funcionando, desde que você lhe passe um dataframe. Essa abordagem exige um pouco mais de código desnecessário.

\newpage

#### Reiniciando índices colunas {.unnumbered}

Por fim, podemos [reiniciar os índices das colunas]{.underline} para que [não tenhamos nomes duplicados]{.underline}.

```{python}
print(pd.concat([df1,df2,df3], axis=1, ignore_index=True))
```

\newpage

### Concatenação com índices diferentes

Os exemplos apresentados [até agora partiram de pressuposto]{.underline} de que estávamos executando uma [concatenação simples de linha ou de coluna]{.underline}. Também foi suposto que a(s) nova(s) linha(s) tinha(m) os mesmos nomes de colunas ou que a(s) coluna(s) tinha(m) os mesmos índices de linha.

Esta seção aborda o que acontece quando os índices das linhas e das colunas não estão alinhados.

#### Concatenando linhas com colunas diferentes

Vamos modificar nossos dataframes para os próximos exemplos:

```{python}
df1.columns = ['A','B','C','D']
df2.columns = ['E','F','G','H']
df3.columns = ['A','C','F','H']
```

```{python}
print(df1)
```

```{python}
print(df2)
```

```{python}
print(df3)
```

\newpage

Se tentarmos concatenar esses dataframes como fizemos anteriormente, os dataframes agora serão muito mais do que simplesmente empilhados uns sobre os outros. [As colunas se alinharão e `NaN` preencherá qualquer área que estaja faltando]{.underline}.

```{python}
row_concat = pd.concat([df1,df2,df3])
print(row_concat)
```

Uma maneira de evitar a inclusão de valores `NaN` é manter [somente as colunas que sejam compartilhadas pela lista de objetos a serem concatenados]{.underline}. Um parâmetro chamado `join` faz isso.

Por padrão, seu valor é `outer`, o que significa que todas as colunas serão mantidas.

Porém, [podemos definir `join='inner'` para manter somente as colunas que sejam compartilhadas entre os conjuntos de dados]{underline}.

Se tentarmos manter apenas as colunas de todos os três dataframes, teremos um dataframe vazio, pois não há nenhuma coluna em comum.

```{python}
print(pd.concat([df1,df2,df3], join='inner'))
```

\newpage

[Se usarmos os dataframes que tenham colunas em comum, somente aquelas que sejam compartilhadas por todos serão devolvidas]{.underline}.

```{python}
print(pd.concat([df1,df3],ignore_index=False, join='inner'))
```

\newpage

#### Concatenando colunas com linhas diferentes

Vamos pegar nossos dataframes e modificá-los novamente de modo que tenham índices de linha diferente. Nesse caso, estamos tomando como base as mesmas modificações de dataframe feitas anteriormente.

```{python}
df1.index = [0,1,2,3]
df2.index = [4,5,6,7]
df3.index = [0,2,5,7]
```

```{python}
print(df1)
```

```{python}
print(df2)
```

```{python}
print(df3)
```

\newpage

Quando concatenamos ao longo de `axis=1`, temos o mesmo resultado de concatenar ao longo de `axis=0`. Os novos dataframes serão somados por coluna, havendo correspondência entre seus respectivos índices de linha. Indicadores de valores ausentes aparecerão nas áreas em que os índices não se alinham.

```{python}
col_concat = pd.concat([df1,df2,df3], axis=1)
print(col_concat)
```

Assim como fizemos quando concatenamos por linha, podemos optar por [manter o resultado somente quando houver índices correspondentes]{.underline} usando [`join=inner`]{.underline}.

```{python}
print(pd.concat([df1,df3],axis=1,join='inner'))
```

\newpage

## Combinando vários conjuntos de dados

A seção anterior fez alusão a alguns conceitos de banco de dados. Os parâmetros `join='inner'` e o default `join='outer'` têm origem no modo de trabalhar com banco de dados quando queremos combinar tabelas.

Em vez de simplesmente ter um índice de linha ou de coluna que queremos usar para concaternar valores, às vezes podemos ter dois ou mais dataframes que queremos combinar com base em valores de dados comuns. Essa tarefa é conhecida no mundo dos bancos de dados como a execução de uma "junção" (`join`).

O Pandas tem um comando `pd.join` que usa `pd.merge` internamente. `join` fará a combinação (`merge`) de objetos com base em um índice, mas o comando `merge` é muito mais explícito e flexível. Se você planeja combinar dataframes pelo índice da linha, por exemplo, poderá consultar a função `join`.

Usaremos conjuntos de dados de pesquisa nessa série de exemplos.

```{python}
person = pd.read_csv('./Data/Cap_04/survey_person.csv')
site = pd.read_csv('./Data/Cap_04/survey_site.csv')
survey = pd.read_csv('./Data/Cap_04/survey_survey.csv')
visited = pd.read_csv('./Data/Cap_04/survey_visited.csv')
```

```{python}
print(person)
```

```{python}
print(site)
```

\newpage

```{python}
print(survey)
```

```{python}
print(visited)
```

\newpage

No momento, nossos dados estão separados em várias partes, cada uma sendo uma unidade de observação. Se quiséssemos observar as datas de cada local, junto com as informações de latitude e longitude desse local, teríamos de [combinar (e fazer um `merge`) de vários dataframes]{.underline}.Isso pode ser feito com a [função `merge` do Pandas]{.underline}. `merge` é, na verdade, um método de `dataframe`.

Quando chamamos esse método, o dataframe chamado será referenciado como '`left`'. Na função `merge`, o primeiro parâmetro é o dataframe '`right`'. O próximo parâmetro indica como o resultado final combinado se parecerá (`how`). A @tbl-pandassql apresenta mais detalhes.

Em seguida, definimos o parâmetro `on`. Ele especifica com quais colunas será feita a correspondência. Se as colunas a esquerda e à direita não tiverem o mesmo nome, poderemos usar os parâmetros `left_on` e `right_on` em seu lugar.

```{python}
#| echo: false
#| error: false
#| warning: false
#| label: tbl-pandassql
#| tbl-cap: Como o parâmetro *how* do **Pandas** se relaciona com o **SQL**

from IPython.display import Markdown
from tabulate import tabulate
table = [["`left`","`left outer`","Mantém todas as **chaves da esquerda**."],
         ["`right`","`right outer`","Mantém todas as **chaves da direita**."],
         ["`outer`","`full outer`","Mantém todas as **chaves** tanto da **esquerda** quanto da **direita**."],
         ["`inner`","`inner`","Mantém **somente** as **chaves** que existem \n**tanto na esquerda quanto na direita**."]
         ]
Markdown(tabulate(
  table, 
  headers=["**Pandas**","**SQL**","Descrição"],
  colalign=("left","left","left")
  ))
```

```{python}
#| echo: false
#| error: false
#| warning: false
#| label: tbl-how-examples
#| tbl-cap: Comportamento do parâmetro `how` no merge

from IPython.display import Markdown
from tabulate import tabulate

table = [
    ["`inner` (padrão)", "Interseção", "Retorna apenas as linhas que possuem chaves \nem ambos os DataFrames."],
    ["`left`","Prioriza a Esquerda", "Mantém todos os dados do DataFrame \nda esquerda e traz o que houver match da direita."],
    ["`right`","Prioriza a Direita", "Mantém todos os dados do DataFrame \nda direita e traz o que houver match da esquerda."],
    ["`outer`","União", "Retorna todos os registros de ambos. \nOnde não houver correspondência, preenche com `NaN`."]
]

Markdown(tabulate(
  table, 
  headers=["Tipo de Join", "Conceito", "Resultado Prático"],
  colalign=("left", "left", "left")
))
```

\newpage

```{python}
#| echo: false
#| error: false
#| warning: false
#| label: tbl-mergeparam
#| tbl-cap: Parâmetros do `merge`

from IPython.display import Markdown
from tabulate import tabulate
table = [["`left`","O primeiro DataFrame (base principal no caso de `left join`)."],
         ["`right`",'O segundo DataFrame (o que será "anexado").'],
         ["`how`","O tipo de união: '`left`', '`right`', '`inner`' (padrão) ou '`outer`'."],
         ["`on`","Nome da coluna usada como chave (quando o nome é igual em ambos)."],
         ["`left_on`","Nome da coluna chave no DataFrame da **esquerda**."],
         ["`right_on`","Nome da coluna chave no DataFrame da **direita**."],
         ["`suffixes`","Sufixos para diferenciar colunas com nomes iguais que não são chaves \n(ex: `_x`, `_y`)."]
         ]
Markdown(tabulate(
  table, 
  headers=["Parâmetro","Função"],
  colalign=("left","left")
  ))
```

\newpage

### `merge` um a um (one-to-one)

No tipo mais simples de `merge`, temos dois dataframes em que queremos fazer a [junção de uma coluna com outra]{.underline}, e as colunas que queremos juntar não contém [nenhum valor duplicado]{.underline}.

Nesse exemplo, modificamos o dataframe `visited` de modo que não haja valores duplicados de `site`.

```{python}
visited_subset = visited.loc[[0,2,6]]
print(visited_subset)
```

Podemos fazer nosso `merge` um a um (***one-to-one***):

```{python}
#O valor default de 'how' é 'inner',
# portanto, não precisa ser especificado.
o2o_merge = site.merge(
   visited_subset,
   left_on='name',
   right_on='site'
)

print(o2o_merge)
```

Como pode ver, criamos agora um novo dataframe a partir de dois dataframes diferentes, em que houve uma correspondência de linhas com base em um conjunto particular de colunas. [No jargão de **SQL**, as colunas usadas na correspondência são chamadas de "**chaves**"]{.underline}.

\newpage

### `merge` de muitos para um (many-to-one)

Se optarmos por fazer o mesmo `merge`, mas dessa vez sem usar o dataframe `visited` como subconjunto, fariamos um [`merge` de muitos para um (***many-to-one***)]{.underline}. Nesse tipo de merge, um dos dataframes tem valores de chave que se repetem.

[Os dataframes contendo as observações únicas serão então duplicados no `merge`]{.underline}.

```{python}
m2o_merge = site.merge(
   visited,
   left_on='name',
   right_on='site'
)

print(m2o_merge)
```

Como podemos ver, as informações de `site`(`name`, `lat` e `long`) foram duplicadas e houve correspondência com os dados de `visited`.

\newpage

### `merge` de muitos para muitos (many-to-many)

Por fim, há ocasiões em que vamos querer efetuar uma correspondência baseada em várias colunas. Como exemplo, suponha que haja dois dataframes, provenientes de um `merge` entre `person` e `survey` e de outro entre `visited` com `survey`.

```{python}
ps = person.merge(
   survey,
   left_on='ident',
   right_on='person'
)

vs = visited.merge(
   survey,
   left_on='ident',
   right_on='taken'
)
```

```{python}
print(ps)
```

```{python}
print(vs)
```

\newpage

Podemos executar um merge de muitos para muitos (***many-to-many***) passando as várias colunas com as quais a correspondência será feita, usando uma lista Python.

```{python}
ps_vs = ps.merge(
   vs,
   left_on=['ident','taken','quant','reading'],
   right_on=['person','ident','quant','reading']
)
```

Vamos observar apenas a primeira linha:

```{python}
print(ps_vs.loc[0,])
```

[O Pandas acrescentará automaticamente um sufixo no nome de uma coluna se houver colisões no nome]{.underline}. Na saída, `_x` refere-se aos valores do dataframe à esquerda, enquanto o sufixo `_y` é proveniente dos valores do dataframe à direita. 

\newpage

### Resumo

O `pd.merge()` funciona de forma similar aos `JOIN`s do **SQL**. O que define o tipo de relação é a frequência com que as chaves de ligação aparecem em cada DataFrame.

1. ***One-to-One*** (Um-para-Um - o2o)

    Ocorre quando a chave de ligação é única em ambos os DataFrames. É como unir duas tabelas de informações diferentes sobre os mesmos indivíduos.

    * **A lógica**: Cada linha da Tabela A encontra exatamente uma linha correspondente na Tabela B.

    * **Impacto nas linhas**: O número de linhas do DataFrame resultante será igual ao número de chaves que coincidem. Nenhuma linha é duplicada; as colunas são apenas "esticadas" para o lado.

    Exemplo: Uma tabela com `ID` e `Nome`, e outra com `ID` e `Cargo`.

2. ***Many-to-One*** (Muitos-para-Um - m2o)

    Ocorre quando uma das tabelas possui chaves repetidas, mas a outra possui apenas chaves únicas. O pandas preserva as repetições e propaga os dados da tabela "única".

    * **A lógica**: Uma linha da Tabela B (o lado "One") corresponde a várias linhas da Tabela A (o lado "Many").

    * **Impacto nas linhas**: As linhas da Tabela A são preservadas. O conteúdo da linha correspondente na Tabela B é copiado para cada uma dessas linhas.

    * **Exemplo visual**: Se o "Vendedor 1" aparece em 10 linhas de vendas, os dados dele (nome, região) serão repetidos nessas 10 linhas no resultado final.

    Exemplo: Uma tabela de **Vendas** (onde o `ID_Vendedor` se repete) e uma tabela de **Vendedores** (onde cada `ID_Vendedor` é único).

3. ***Many-to-Many*** (Muitos-para-Muitos - m2m)

    Ocorre quando a chave de ligação se repete em ambos os DataFrames. O resultado é um produto cartesiano das linhas correspondentes.

    * **A lógica**: Uma chave aparece N vezes na Tabela A e M vezes na Tabela B.

    * **Impacto nas linhas**: O Pandas cria todas as combinações possíveis entre elas. O número de linhas resultantes para aquela chave específica será $N \times M$.

    * **Atenção**: Este é o caso mais perigoso, pois pode gerar um aumento explosivo no tamanho do seu DataFrame se você não estiver esperando por essas combinações.

    Exemplo: Uma tabela de Produtos em promoção e uma tabela de Lojas que vendem esses produtos. Se um produto aparece 3 vezes na Tabela A e 2 vezes na Tabela B, o resultado terá $3 \times 2 = 6$ linhas para essa chave.

\newpage

## Conclusão preparação dos dados

As vezes, [será preciso combinar diversas partes ou dados ou vários conjuntos de dados, conforme a pergunta que tiver tentano responder]{.underline}. Tenha em mente, porém, que os dados de que você precisar nas análises não estarão necessariamente no melhor formato usado para armazená-los.

Os dados de pesquisa usados no último exemplo estavam separados em quatro partes que precisam ser combinadas. Depois que fizemos o `merge` das tabelas, muitas informações redundantes apareceram nas linhas. [Do ponto de vista da armazenagem de dados e de sua entrada, cada uma dessas duplicações pode lever a erros e inconsistência nos dados]{.underline}. É isso que Hadley quis dizer quando afirmou que, nos dados organizados (***Tidy data***), "cada tipo de unidade de observação forma uma tabela".

\newpage

# Dados Ausentes

## Introdução
## O que é um valor `NaN`?
## De onde vêm os valores ausentes?
## Trabalhando com dados ausentes
## Conclusão dados ausentes

\newpage

# Tidy data (dados organizados)

\newpage

# Referências